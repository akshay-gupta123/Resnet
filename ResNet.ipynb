{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPAtLxKS++5VkQUxHJcr5qG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshay-gupta123/Resnet/blob/master/ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP23dGEtXSAt",
        "colab_type": "code",
        "outputId": "3872779a-5442-4f1b-832f-b64990547da2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as od\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WvytC5SXjGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgdyruE-YB2B",
        "colab_type": "code",
        "outputId": "5d6c12f9-dc70-444f-a92a-5decb810a1b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysT0SOPJYTIW",
        "colab_type": "code",
        "outputId": "a81d23b0-3bec-486d-d1dd-1e3992e2394d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1UpgsEJYs6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    lr = 1e-1\n",
        "    if epoch >=35:\n",
        "      lr *= 5e-3\n",
        "    elif epoch >=25:\n",
        "      lr*=1e-2\n",
        "    elif epoch >=15:\n",
        "      lr*=1e-1\n",
        "\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaZNd5jqZIIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "           \n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='glorot_normal',\n",
        "                  kernel_regularizer=l2(0.01))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpX0_x5iZPq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGEybY-AZrgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \n",
        "    # Start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    \n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "    \n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FYw1JBCZ5xz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1 = resnet_v2(input_shape=input_shape, depth=38)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtVX7S1FZ-_R",
        "colab_type": "code",
        "outputId": "68c73a66-8d36-46ec-a9a0-98d4f90aeaad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(momentum=0.9,decay=.005,learning_rate=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model_1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.1\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 32, 32, 16)   448         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 32, 32, 16)   64          conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 32, 32, 16)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 32, 32, 16)   272         activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 32, 32, 16)   64          conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 32, 32, 16)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 32, 32, 16)   2320        activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 32, 32, 16)   64          conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 32, 32, 16)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 32, 32, 64)   1088        activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 32, 32, 64)   1088        activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 32, 32, 64)   0           conv2d_114[0][0]                 \n",
            "                                                                 conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 32, 32, 64)   256         add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 32, 32, 64)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 32, 32, 16)   1040        activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 32, 32, 16)   64          conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 32, 32, 16)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 32, 32, 16)   2320        activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 32, 32, 16)   64          conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 32, 32, 16)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 32, 32, 64)   1088        activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 32, 32, 64)   0           add_43[0][0]                     \n",
            "                                                                 conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 32, 32, 64)   256         add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 32, 32, 64)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 32, 32, 16)   1040        activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 32, 32, 16)   64          conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 32, 32, 16)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 32, 32, 16)   2320        activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 32, 32, 16)   64          conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 32, 32, 16)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 32, 32, 64)   1088        activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 32, 32, 64)   0           add_44[0][0]                     \n",
            "                                                                 conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 32, 32, 64)   256         add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 32, 32, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 32, 32, 16)   1040        activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 32, 32, 16)   64          conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 32, 32, 16)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 32, 32, 16)   2320        activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 32, 32, 16)   64          conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 32, 32, 16)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 32, 32, 64)   1088        activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 32, 32, 64)   0           add_45[0][0]                     \n",
            "                                                                 conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 32, 32, 64)   256         add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 32, 32, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 16, 16, 64)   4160        activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 16, 16, 64)   256         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 16, 16, 64)   36928       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 16, 16, 64)   256         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 16, 16, 64)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 16, 16, 128)  8320        add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 16, 16, 128)  8320        activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 16, 16, 128)  0           conv2d_127[0][0]                 \n",
            "                                                                 conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 16, 16, 128)  512         add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 16, 16, 128)  0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 16, 16, 64)   8256        activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 16, 16, 64)   256         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 16, 16, 64)   36928       activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 16, 16, 64)   256         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 16, 16, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 16, 16, 128)  8320        activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_48 (Add)                    (None, 16, 16, 128)  0           add_47[0][0]                     \n",
            "                                                                 conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 128)  512         add_48[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 16, 16, 128)  0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 16, 16, 64)   8256        activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 16, 16, 64)   256         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 16, 16, 64)   0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 16, 16, 64)   36928       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 16, 16, 64)   256         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 16, 16, 64)   0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 16, 16, 128)  8320        activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_49 (Add)                    (None, 16, 16, 128)  0           add_48[0][0]                     \n",
            "                                                                 conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 16, 16, 128)  512         add_49[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 16, 16, 128)  0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 16, 16, 64)   8256        activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 16, 16, 64)   256         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 16, 16, 64)   0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 16, 16, 64)   36928       activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 16, 16, 64)   256         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 16, 16, 64)   0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 16, 16, 128)  8320        activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_50 (Add)                    (None, 16, 16, 128)  0           add_49[0][0]                     \n",
            "                                                                 conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 16, 16, 128)  512         add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 16, 16, 128)  0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 8, 8, 128)    16512       activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 8, 8, 128)    512         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 8, 8, 128)    0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 8, 8, 128)    147584      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 8, 8, 128)    512         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 8, 8, 128)    0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 8, 8, 256)    33024       add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 8, 8, 256)    33024       activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_51 (Add)                    (None, 8, 8, 256)    0           conv2d_140[0][0]                 \n",
            "                                                                 conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 8, 8, 256)    1024        add_51[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 8, 8, 256)    0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 8, 8, 128)    32896       activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 8, 8, 128)    512         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 8, 8, 128)    0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 8, 8, 128)    147584      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 8, 8, 128)    512         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 8, 8, 128)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 8, 8, 256)    33024       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_52 (Add)                    (None, 8, 8, 256)    0           add_51[0][0]                     \n",
            "                                                                 conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 8, 8, 256)    1024        add_52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 8, 8, 256)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 8, 8, 128)    32896       activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 8, 8, 128)    512         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 8, 8, 128)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 8, 8, 128)    147584      activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 8, 8, 128)    512         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 8, 8, 128)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 8, 8, 256)    33024       activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_53 (Add)                    (None, 8, 8, 256)    0           add_52[0][0]                     \n",
            "                                                                 conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 8, 8, 256)    1024        add_53[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 8, 8, 256)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 8, 8, 128)    32896       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 8, 8, 128)    512         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 8, 8, 128)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 8, 8, 128)    147584      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 8, 8, 128)    512         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 8, 8, 128)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 8, 8, 256)    33024       activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_54 (Add)                    (None, 8, 8, 256)    0           add_53[0][0]                     \n",
            "                                                                 conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 8, 8, 256)    1024        add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 8, 8, 256)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 1, 1, 256)    0           activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 256)          0           average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 10)           2570        flatten_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,123,914\n",
            "Trainable params: 1,116,970\n",
            "Non-trainable params: 6,944\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmYE1z0yaEDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_v2_model.{epoch:02d}.h5'\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXFDHqjQaMx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=0.1,\n",
        "                               cooldown=2,\n",
        "                               patience=3,\n",
        "                               modec='auto',\n",
        "                               verbose=1,\n",
        "                               min_lr=1e-4)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSerdhTictLe",
        "colab_type": "code",
        "outputId": "a037a898-527b-46d4-9666-0c0d3ccc2a85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model_1.fit(x_train, y_train,\n",
        "              batch_size= 64,\n",
        "              epochs=40,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 133s 3ms/step - loss: 3.3396 - accuracy: 0.3604 - val_loss: 2.9493 - val_accuracy: 0.1944\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.19440, saving model to /content/saved_models/cifar10_ResNet26v1_model.001.h5\n",
            "Epoch 2/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 125s 3ms/step - loss: 1.6164 - accuracy: 0.4979 - val_loss: 3.0779 - val_accuracy: 0.1884\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.19440\n",
            "Epoch 3/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 1.4180 - accuracy: 0.5832 - val_loss: 1.7686 - val_accuracy: 0.4732\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.19440 to 0.47320, saving model to /content/saved_models/cifar10_ResNet26v1_model.003.h5\n",
            "Epoch 4/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 1.2963 - accuracy: 0.6321 - val_loss: 1.6157 - val_accuracy: 0.5220\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.47320 to 0.52200, saving model to /content/saved_models/cifar10_ResNet26v1_model.004.h5\n",
            "Epoch 5/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 1.2058 - accuracy: 0.6703 - val_loss: 1.3298 - val_accuracy: 0.6209\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.52200 to 0.62090, saving model to /content/saved_models/cifar10_ResNet26v1_model.005.h5\n",
            "Epoch 6/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 1.1241 - accuracy: 0.6977 - val_loss: 1.4506 - val_accuracy: 0.5826\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.62090\n",
            "Epoch 7/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 1.0555 - accuracy: 0.7260 - val_loss: 1.2175 - val_accuracy: 0.6704\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.62090 to 0.67040, saving model to /content/saved_models/cifar10_ResNet26v1_model.007.h5\n",
            "Epoch 8/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.9992 - accuracy: 0.7476 - val_loss: 1.1646 - val_accuracy: 0.6884\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.67040 to 0.68840, saving model to /content/saved_models/cifar10_ResNet26v1_model.008.h5\n",
            "Epoch 9/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.9552 - accuracy: 0.7669 - val_loss: 1.1061 - val_accuracy: 0.7165\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.68840 to 0.71650, saving model to /content/saved_models/cifar10_ResNet26v1_model.009.h5\n",
            "Epoch 10/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.9134 - accuracy: 0.7794 - val_loss: 1.1830 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.71650\n",
            "Epoch 11/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.8792 - accuracy: 0.7926 - val_loss: 1.2554 - val_accuracy: 0.6670\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.71650\n",
            "Epoch 12/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.8495 - accuracy: 0.8030 - val_loss: 1.3803 - val_accuracy: 0.6385\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.71650\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
            "Epoch 13/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.8218 - accuracy: 0.8130 - val_loss: 1.4008 - val_accuracy: 0.6560\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.71650\n",
            "Epoch 14/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 125s 2ms/step - loss: 0.8002 - accuracy: 0.8192 - val_loss: 0.9858 - val_accuracy: 0.7562\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.71650 to 0.75620, saving model to /content/saved_models/cifar10_ResNet26v1_model.014.h5\n",
            "Epoch 15/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.7772 - accuracy: 0.8280 - val_loss: 1.4091 - val_accuracy: 0.6384\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.75620\n",
            "Epoch 16/40\n",
            "Learning rate:  0.010000000000000002\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.6077 - accuracy: 0.8888 - val_loss: 0.6916 - val_accuracy: 0.8541\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.75620 to 0.85410, saving model to /content/saved_models/cifar10_ResNet26v1_model.016.h5\n",
            "Epoch 17/40\n",
            "Learning rate:  0.010000000000000002\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.5200 - accuracy: 0.9147 - val_loss: 0.6734 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.85410 to 0.85710, saving model to /content/saved_models/cifar10_ResNet26v1_model.017.h5\n",
            "Epoch 18/40\n",
            "Learning rate:  0.010000000000000002\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.4777 - accuracy: 0.9250 - val_loss: 0.6679 - val_accuracy: 0.8573\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.85710 to 0.85730, saving model to /content/saved_models/cifar10_ResNet26v1_model.018.h5\n",
            "Epoch 19/40\n",
            "Learning rate:  0.010000000000000002\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.4411 - accuracy: 0.9349 - val_loss: 0.6590 - val_accuracy: 0.8582\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.85730 to 0.85820, saving model to /content/saved_models/cifar10_ResNet26v1_model.019.h5\n",
            "Epoch 20/40\n",
            "Learning rate:  0.010000000000000002\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.4081 - accuracy: 0.9433 - val_loss: 0.6684 - val_accuracy: 0.8546\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.85820\n",
            "Epoch 21/40\n",
            "Learning rate:  0.010000000000000002\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.3765 - accuracy: 0.9526 - val_loss: 0.6557 - val_accuracy: 0.8574\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.85820\n",
            "Epoch 22/40\n",
            "Learning rate:  0.010000000000000002\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.3464 - accuracy: 0.9615 - val_loss: 0.6981 - val_accuracy: 0.8475\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.85820\n",
            "Epoch 23/40\n",
            "Learning rate:  0.010000000000000002\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.3223 - accuracy: 0.9679 - val_loss: 0.6700 - val_accuracy: 0.8553\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.85820\n",
            "Epoch 24/40\n",
            "Learning rate:  0.010000000000000002\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.3015 - accuracy: 0.9716 - val_loss: 0.6914 - val_accuracy: 0.8549\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.85820\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "Epoch 25/40\n",
            "Learning rate:  0.010000000000000002\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.2815 - accuracy: 0.9778 - val_loss: 0.6998 - val_accuracy: 0.8481\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.85820\n",
            "Epoch 26/40\n",
            "Learning rate:  0.001\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.2524 - accuracy: 0.9890 - val_loss: 0.6690 - val_accuracy: 0.8589\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.85820 to 0.85890, saving model to /content/saved_models/cifar10_ResNet26v1_model.026.h5\n",
            "Epoch 27/40\n",
            "Learning rate:  0.001\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.2444 - accuracy: 0.9918 - val_loss: 0.6696 - val_accuracy: 0.8592\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.85890 to 0.85920, saving model to /content/saved_models/cifar10_ResNet26v1_model.027.h5\n",
            "Epoch 28/40\n",
            "Learning rate:  0.001\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.2392 - accuracy: 0.9935 - val_loss: 0.6719 - val_accuracy: 0.8578\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.85920\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 29/40\n",
            "Learning rate:  0.001\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.2366 - accuracy: 0.9938 - val_loss: 0.6758 - val_accuracy: 0.8594\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.85920 to 0.85940, saving model to /content/saved_models/cifar10_ResNet26v1_model.029.h5\n",
            "Epoch 30/40\n",
            "Learning rate:  0.001\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.2345 - accuracy: 0.9943 - val_loss: 0.6789 - val_accuracy: 0.8574\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.85940\n",
            "Epoch 31/40\n",
            "Learning rate:  0.001\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.2320 - accuracy: 0.9952 - val_loss: 0.6791 - val_accuracy: 0.8574\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.85940\n",
            "Epoch 32/40\n",
            "Learning rate:  0.001\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.2308 - accuracy: 0.9957 - val_loss: 0.6805 - val_accuracy: 0.8580\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.85940\n",
            "\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 33/40\n",
            "Learning rate:  0.001\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.2290 - accuracy: 0.9955 - val_loss: 0.6837 - val_accuracy: 0.8582\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.85940\n",
            "Epoch 34/40\n",
            "Learning rate:  0.001\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.2282 - accuracy: 0.9955 - val_loss: 0.6844 - val_accuracy: 0.8583\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.85940\n",
            "Epoch 35/40\n",
            "Learning rate:  0.001\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.2265 - accuracy: 0.9964 - val_loss: 0.6861 - val_accuracy: 0.8586\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.85940\n",
            "Epoch 36/40\n",
            "Learning rate:  0.0005\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.2254 - accuracy: 0.9965 - val_loss: 0.6860 - val_accuracy: 0.8570\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.85940\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "Epoch 37/40\n",
            "Learning rate:  0.0005\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.2248 - accuracy: 0.9963 - val_loss: 0.6876 - val_accuracy: 0.8577\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.85940\n",
            "Epoch 38/40\n",
            "Learning rate:  0.0005\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.2247 - accuracy: 0.9958 - val_loss: 0.6874 - val_accuracy: 0.8577\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.85940\n",
            "Epoch 39/40\n",
            "Learning rate:  0.0005\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.2230 - accuracy: 0.9965 - val_loss: 0.6884 - val_accuracy: 0.8578\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.85940\n",
            "Epoch 40/40\n",
            "Learning rate:  0.0005\n",
            "50000/50000 [==============================] - 124s 2ms/step - loss: 0.2228 - accuracy: 0.9966 - val_loss: 0.6894 - val_accuracy: 0.8570\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.85940\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0001.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38UgNnnHRviF",
        "colab_type": "code",
        "outputId": "aab03331-93d2-47e7-88fa-c10235a3d590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "history_df = od.DataFrame(history.history) \n",
        "history_df[['loss', 'val_loss']].plot()\n",
        "history_df = od.DataFrame(history.history) \n",
        "history_df[['accuracy', 'val_accuracy']].plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1b8b0896a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtMGkKmQ0jrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2 = resnet_v1(input_shape=input_shape, depth=26)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c51j4Gg51AEK",
        "colab_type": "code",
        "outputId": "d85ce79f-7f1a-4543-d6e5-e726a442d465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(momentum=0.9,decay=.005,learning_rate=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model_2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.1\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 32, 32, 16)   448         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 32, 32, 16)   64          conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 32, 32, 16)   0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 32, 32, 16)   2320        activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 32, 32, 16)   64          conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 32, 32, 16)   0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 32, 32, 16)   2320        activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 32, 32, 16)   64          conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_55 (Add)                    (None, 32, 32, 16)   0           activation_140[0][0]             \n",
            "                                                                 batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 32, 32, 16)   0           add_55[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 32, 32, 16)   2320        activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 32, 32, 16)   64          conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 32, 32, 16)   0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 32, 32, 16)   2320        activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 32, 32, 16)   64          conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_56 (Add)                    (None, 32, 32, 16)   0           activation_142[0][0]             \n",
            "                                                                 batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 32, 32, 16)   0           add_56[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 32, 32, 16)   2320        activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 32, 32, 16)   64          conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 32, 32, 16)   0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 32, 32, 16)   2320        activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 32, 32, 16)   64          conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_57 (Add)                    (None, 32, 32, 16)   0           activation_144[0][0]             \n",
            "                                                                 batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 32, 32, 16)   0           add_57[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 32, 32, 16)   2320        activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 32, 32, 16)   64          conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 32, 32, 16)   0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 32, 32, 16)   2320        activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 32, 32, 16)   64          conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_58 (Add)                    (None, 32, 32, 16)   0           activation_146[0][0]             \n",
            "                                                                 batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 32, 32, 16)   0           add_58[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 16, 16, 32)   4640        activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 16, 16, 32)   128         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 16, 16, 32)   0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 16, 16, 32)   9248        activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 16, 16, 32)   544         activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 16, 16, 32)   128         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_59 (Add)                    (None, 16, 16, 32)   0           conv2d_161[0][0]                 \n",
            "                                                                 batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 16, 16, 32)   0           add_59[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 16, 16, 32)   9248        activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 16, 16, 32)   128         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 16, 16, 32)   0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 16, 16, 32)   9248        activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 16, 16, 32)   128         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_60 (Add)                    (None, 16, 16, 32)   0           activation_150[0][0]             \n",
            "                                                                 batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 16, 16, 32)   0           add_60[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 16, 16, 32)   9248        activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 16, 16, 32)   128         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 16, 16, 32)   0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 16, 16, 32)   9248        activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 16, 16, 32)   128         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_61 (Add)                    (None, 16, 16, 32)   0           activation_152[0][0]             \n",
            "                                                                 batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 16, 16, 32)   0           add_61[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 16, 16, 32)   9248        activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 16, 16, 32)   128         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 16, 16, 32)   0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 16, 16, 32)   9248        activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 16, 16, 32)   128         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_62 (Add)                    (None, 16, 16, 32)   0           activation_154[0][0]             \n",
            "                                                                 batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 16, 16, 32)   0           add_62[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 8, 8, 64)     18496       activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 8, 8, 64)     256         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 8, 8, 64)     0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 8, 8, 64)     36928       activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 8, 8, 64)     2112        activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 8, 8, 64)     256         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_63 (Add)                    (None, 8, 8, 64)     0           conv2d_170[0][0]                 \n",
            "                                                                 batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 8, 8, 64)     0           add_63[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 8, 8, 64)     36928       activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 8, 8, 64)     256         conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 8, 8, 64)     0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 8, 8, 64)     36928       activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 8, 8, 64)     256         conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_64 (Add)                    (None, 8, 8, 64)     0           activation_158[0][0]             \n",
            "                                                                 batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 8, 8, 64)     0           add_64[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 8, 8, 64)     36928       activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 8, 8, 64)     256         conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 8, 8, 64)     0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 8, 8, 64)     36928       activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 8, 8, 64)     256         conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_65 (Add)                    (None, 8, 8, 64)     0           activation_160[0][0]             \n",
            "                                                                 batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 8, 8, 64)     0           add_65[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 8, 8, 64)     36928       activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 8, 8, 64)     256         conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 8, 8, 64)     0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 8, 8, 64)     36928       activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 8, 8, 64)     256         conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_66 (Add)                    (None, 8, 8, 64)     0           activation_162[0][0]             \n",
            "                                                                 batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 8, 8, 64)     0           add_66[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 8, 8, 64)     256         activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 1, 1, 64)     0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 64)           0           average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 10)           650         flatten_5[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 372,586\n",
            "Trainable params: 370,634\n",
            "Non-trainable params: 1,952\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNkSXmc61ckn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_v1_model.{epoch:02d}.h5' \n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT-2FV382uid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=0.1,\n",
        "                               cooldown=2,\n",
        "                               patience=3,\n",
        "                               modec='auto',\n",
        "                               verbose=1,\n",
        "                               min_lr=1e-4)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sGUku-m1kLh",
        "colab_type": "code",
        "outputId": "343d6128-b01d-4565-97be-069adccbb9d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_1 = model_2.fit(x_train, y_train,\n",
        "              batch_size= 64,\n",
        "              epochs=40,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 50s 1ms/step - loss: 1.0091 - accuracy: 0.7487 - val_loss: 1.8476 - val_accuracy: 0.4969\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.49690, saving model to /content/saved_models/cifar10_v2_model.001.h5\n",
            "Epoch 2/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 50s 1ms/step - loss: 0.9577 - accuracy: 0.7668 - val_loss: 1.5891 - val_accuracy: 0.5972\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.49690 to 0.59720, saving model to /content/saved_models/cifar10_v2_model.002.h5\n",
            "Epoch 3/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 50s 1ms/step - loss: 0.9165 - accuracy: 0.7827 - val_loss: 1.4494 - val_accuracy: 0.6259\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.59720 to 0.62590, saving model to /content/saved_models/cifar10_v2_model.003.h5\n",
            "Epoch 4/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 50s 1ms/step - loss: 0.8808 - accuracy: 0.7925 - val_loss: 1.5239 - val_accuracy: 0.6065\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.62590\n",
            "Epoch 5/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 50s 1ms/step - loss: 0.8468 - accuracy: 0.8032 - val_loss: 1.1732 - val_accuracy: 0.6905\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.62590 to 0.69050, saving model to /content/saved_models/cifar10_v2_model.005.h5\n",
            "Epoch 6/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 50s 1ms/step - loss: 0.8223 - accuracy: 0.8114 - val_loss: 1.4081 - val_accuracy: 0.6192\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.69050\n",
            "Epoch 7/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 50s 1ms/step - loss: 0.7929 - accuracy: 0.8216 - val_loss: 1.0886 - val_accuracy: 0.7226\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.69050 to 0.72260, saving model to /content/saved_models/cifar10_v2_model.007.h5\n",
            "Epoch 8/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 50s 1ms/step - loss: 0.7662 - accuracy: 0.8309 - val_loss: 0.9966 - val_accuracy: 0.7537\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.72260 to 0.75370, saving model to /content/saved_models/cifar10_v2_model.008.h5\n",
            "Epoch 9/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 51s 1ms/step - loss: 0.7447 - accuracy: 0.8378 - val_loss: 1.0435 - val_accuracy: 0.7439\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.75370\n",
            "Epoch 10/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 52s 1ms/step - loss: 0.7233 - accuracy: 0.8432 - val_loss: 1.2350 - val_accuracy: 0.6936\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.75370\n",
            "Epoch 11/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 52s 1ms/step - loss: 0.7052 - accuracy: 0.8496 - val_loss: 1.0594 - val_accuracy: 0.7403\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.75370\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
            "Epoch 12/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 52s 1ms/step - loss: 0.6925 - accuracy: 0.8535 - val_loss: 1.2172 - val_accuracy: 0.6934\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.75370\n",
            "Epoch 13/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 52s 1ms/step - loss: 0.6721 - accuracy: 0.8612 - val_loss: 1.0880 - val_accuracy: 0.7411\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.75370\n",
            "Epoch 14/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 52s 1ms/step - loss: 0.6587 - accuracy: 0.8658 - val_loss: 1.0580 - val_accuracy: 0.7376\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.75370\n",
            "Epoch 15/40\n",
            "Learning rate:  0.1\n",
            "50000/50000 [==============================] - 52s 1ms/step - loss: 0.6458 - accuracy: 0.8707 - val_loss: 1.1256 - val_accuracy: 0.7309\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.75370\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
            "Epoch 16/40\n",
            "Learning rate:  0.010000000000000002\n",
            "50000/50000 [==============================] - 52s 1ms/step - loss: 0.4961 - accuracy: 0.9246 - val_loss: 0.6687 - val_accuracy: 0.8609\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.75370 to 0.86090, saving model to /content/saved_models/cifar10_v2_model.016.h5\n",
            "Epoch 17/40\n",
            "Learning rate:  0.010000000000000002\n",
            "50000/50000 [==============================] - 52s 1ms/step - loss: 0.4176 - accuracy: 0.9489 - val_loss: 0.6617 - val_accuracy: 0.8657\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.86090 to 0.86570, saving model to /content/saved_models/cifar10_v2_model.017.h5\n",
            "Epoch 18/40\n",
            "Learning rate:  0.010000000000000002\n",
            "50000/50000 [==============================] - 52s 1ms/step - loss: 0.3790 - accuracy: 0.9592 - val_loss: 0.6580 - val_accuracy: 0.8638\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.86570\n",
            "Epoch 19/40\n",
            "Learning rate:  0.010000000000000002\n",
            "50000/50000 [==============================] - 50s 1ms/step - loss: 0.3507 - accuracy: 0.9663 - val_loss: 0.6746 - val_accuracy: 0.8628\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.86570\n",
            "Epoch 20/40\n",
            "Learning rate:  0.010000000000000002\n",
            "50000/50000 [==============================] - 50s 1000us/step - loss: 0.3236 - accuracy: 0.9732 - val_loss: 0.6888 - val_accuracy: 0.8622\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.86570\n",
            "Epoch 21/40\n",
            "Learning rate:  0.010000000000000002\n",
            "50000/50000 [==============================] - 50s 1ms/step - loss: 0.3017 - accuracy: 0.9794 - val_loss: 0.6987 - val_accuracy: 0.8611\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.86570\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "Epoch 22/40\n",
            "Learning rate:  0.010000000000000002\n",
            "50000/50000 [==============================] - 50s 1ms/step - loss: 0.2839 - accuracy: 0.9841 - val_loss: 0.7094 - val_accuracy: 0.8625\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.86570\n",
            "Epoch 23/40\n",
            "Learning rate:  0.010000000000000002\n",
            "50000/50000 [==============================] - 50s 999us/step - loss: 0.2681 - accuracy: 0.9870 - val_loss: 0.7291 - val_accuracy: 0.8597\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.86570\n",
            "Epoch 24/40\n",
            "Learning rate:  0.010000000000000002\n",
            "50000/50000 [==============================] - 50s 1000us/step - loss: 0.2533 - accuracy: 0.9903 - val_loss: 0.7452 - val_accuracy: 0.8564\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.86570\n",
            "Epoch 25/40\n",
            "Learning rate:  0.010000000000000002\n",
            "50000/50000 [==============================] - 50s 997us/step - loss: 0.2410 - accuracy: 0.9923 - val_loss: 0.7299 - val_accuracy: 0.8622\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.86570\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "Epoch 26/40\n",
            "Learning rate:  0.001\n",
            "50000/50000 [==============================] - 50s 996us/step - loss: 0.2294 - accuracy: 0.9957 - val_loss: 0.7280 - val_accuracy: 0.8639\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.86570\n",
            "Epoch 27/40\n",
            "Learning rate:  0.001\n",
            "50000/50000 [==============================] - 50s 995us/step - loss: 0.2275 - accuracy: 0.9963 - val_loss: 0.7267 - val_accuracy: 0.8638\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.86570\n",
            "Epoch 28/40\n",
            "Learning rate:  0.001\n",
            "50000/50000 [==============================] - 50s 994us/step - loss: 0.2249 - accuracy: 0.9965 - val_loss: 0.7289 - val_accuracy: 0.8625\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.86570\n",
            "Epoch 29/40\n",
            "Learning rate:  0.001\n",
            "50000/50000 [==============================] - 50s 995us/step - loss: 0.2237 - accuracy: 0.9971 - val_loss: 0.7303 - val_accuracy: 0.8626\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.86570\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 30/40\n",
            "Learning rate:  0.001\n",
            "50000/50000 [==============================] - 50s 997us/step - loss: 0.2227 - accuracy: 0.9972 - val_loss: 0.7313 - val_accuracy: 0.8632\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.86570\n",
            "Epoch 31/40\n",
            "Learning rate:  0.001\n",
            "50000/50000 [==============================] - 50s 995us/step - loss: 0.2220 - accuracy: 0.9976 - val_loss: 0.7339 - val_accuracy: 0.8624\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.86570\n",
            "Epoch 32/40\n",
            "Learning rate:  0.001\n",
            "50000/50000 [==============================] - 50s 995us/step - loss: 0.2208 - accuracy: 0.9972 - val_loss: 0.7329 - val_accuracy: 0.8629\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.86570\n",
            "Epoch 33/40\n",
            "Learning rate:  0.001\n",
            "50000/50000 [==============================] - 50s 994us/step - loss: 0.2202 - accuracy: 0.9976 - val_loss: 0.7343 - val_accuracy: 0.8631\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.86570\n",
            "\n",
            "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 34/40\n",
            "Learning rate:  0.001\n",
            "50000/50000 [==============================] - 50s 995us/step - loss: 0.2195 - accuracy: 0.9977 - val_loss: 0.7357 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.86570\n",
            "Epoch 35/40\n",
            "Learning rate:  0.001\n",
            "50000/50000 [==============================] - 50s 994us/step - loss: 0.2192 - accuracy: 0.9977 - val_loss: 0.7364 - val_accuracy: 0.8635\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.86570\n",
            "Epoch 36/40\n",
            "Learning rate:  0.0005\n",
            "50000/50000 [==============================] - 50s 998us/step - loss: 0.2181 - accuracy: 0.9979 - val_loss: 0.7376 - val_accuracy: 0.8628\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.86570\n",
            "Epoch 37/40\n",
            "Learning rate:  0.0005\n",
            "50000/50000 [==============================] - 50s 998us/step - loss: 0.2180 - accuracy: 0.9976 - val_loss: 0.7377 - val_accuracy: 0.8622\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.86570\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "Epoch 38/40\n",
            "Learning rate:  0.0005\n",
            "50000/50000 [==============================] - 50s 995us/step - loss: 0.2169 - accuracy: 0.9981 - val_loss: 0.7371 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.86570\n",
            "Epoch 39/40\n",
            "Learning rate:  0.0005\n",
            "50000/50000 [==============================] - 50s 997us/step - loss: 0.2174 - accuracy: 0.9977 - val_loss: 0.7376 - val_accuracy: 0.8615\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.86570\n",
            "Epoch 40/40\n",
            "Learning rate:  0.0005\n",
            "50000/50000 [==============================] - 50s 995us/step - loss: 0.2172 - accuracy: 0.9979 - val_loss: 0.7392 - val_accuracy: 0.8627\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.86570\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVkyzyyQ1r92",
        "colab_type": "code",
        "outputId": "a29e18ca-66a3-441e-95b5-703772021a82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "history_df = od.DataFrame(history_1.history) \n",
        "history_df[['loss', 'val_loss']].plot()\n",
        "history_df = od.DataFrame(history_1.history) \n",
        "history_df[['accuracy', 'val_accuracy']].plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1b8910a7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxU9b3/8dd3JpOELIRsBAhLAoQdZAm4C0hRrBQUS5Hrz60qWtdqN7VWbS/2env1Wq3Wil5361IqFq0rizsIYV9NwpqE7CQhAbLNfH9/fCdhCFkmYSYnM/k8H4/zmJkzZ858cpK85zvfc873KK01QgghAp/N6gKEEEL4hgS6EEIECQl0IYQIEhLoQggRJCTQhRAiSIRY9cYJCQk6JSXFqrcXQoiAtGHDhhKtdWJzz1kW6CkpKWRkZFj19kIIEZCUUgdaek66XIQQIkhIoAshRJCQQBdCiCBhWR96c+rq6sjNzaW6utrqUgQQHh5O//79cTgcVpcihPBCm4GulHoRmA0Uaa3HNPO8Ap4EfggcA67TWm/sSDG5ublER0eTkpKCWa2witaa0tJScnNzSU1NtbocIYQXvOlyeRmY1crzlwBp7mkR8GxHi6muriY+Pl7CvAtQShEfHy/floQIIG0Gutb6S+BwK4vMBV7Vxlqgl1Kqb0cLkjDvOuR3IURg8UUfejKQ4/E41z0v3wfrFkJ0Eq019S5Nbb2LmnoXtfUu6l0utMZMaFzaLNdwW+/SOF3mtt7panxc53Th0hq7zYbDpgix2wixKxw2961doZSi3qmpd7ma3JrJ5dK49MnvSWMNbfwsJ9WqcbrApXXjelxaY1MKu1LYbAq7DWxKmXk205Cpc5ptUOfUjfdrnS7qnGabOOzun8umCA2xEeL5s6Eaa/d8X6fL3J+SGs/wPtE+/x126k5RpdQiTLcMAwcO7My3FiJolB2t5fvCSr4vqORA6TGq653U1LmoqXdS0xjGzsZQNiECTm1C0qlN6LpcmrrGAHdSW+9yh6bwt8WXjemygZ4HDPB43N897xRa6yXAEoD09PRu/adTX19PSEiXOshIdCF1ThclVTUUVFSTVVTF9wWVZBZWsrugkuLKmsblIkLtRISGEBZiI8xhIyzETmiIjbAQG1FhIYRG2EwLVCls7lao3XaiZRpiU+7X2gkLsRFqN+sJtdsIDbETYlMoZbrfbAqUMutQSqGAEJtZn8Nuw25ThNgVITZz325TOF2mhVvv1NQ1tMDdLXmX1o2t2hB3K97hfl2I3YZNgd1mWrvqpPemcV5rbOpEq9vm8fM3rMPV+MHmvu/xgQfgsDdsBxsOuw2H3bTEHTYbSkG9+5tInftnamjJ17s/FW0e9Z6oA2w2RVSYf/73fbHW5cDtSqm3gDOBCq11QHe3XHbZZeTk5FBdXc1dd93FokWL+Pjjj7n//vtxOp0kJCSwcuVKqqqquOOOO8jIyEApxUMPPcQVV1xBVFQUVVVVACxdupQPPviAl19+meuuu47w8HA2bdrEueeey5VXXsldd91FdXU1PXr04KWXXmL48OE4nU5+85vf8PHHH2Oz2bjpppsYPXo0Tz31FO+99x4An332GX/9619ZtmyZlZtKdFD5sVoyC6vIKqokv7yawiPVFFXWUFRZQ3FlNaVHa0/qVgh32BiWFM3UYYkMT4pmWJ9ohidFk9QzTPZ1WMRhNx9kXYk3hy2+CUwDEpRSucBDgANAa/034EPMIYvZmMMWr/dFYb9/fwc7Dx3xxaoajerXk4d+NLrN5V588UXi4uI4fvw4kydPZu7cudx00018+eWXpKamcviw2Uf8n//5n8TExLBt2zYAysrK2lx3bm4u3377LXa7nSNHjvDVV18REhLCihUruP/++/nnP//JkiVL2L9/P5s3byYkJITDhw8TGxvLrbfeSnFxMYmJibz00kv89Kc/Pb0NIvyu/Fgt2UVVZBZWkVlYSVZRJZmFVSe1su02RUJUKL2jw0nuFc74Ab3oHR1GUs9wknqGMSQxigFxEY19u0K0pM1A11ovbON5Ddzms4q6gKeeeqqx5ZuTk8OSJUu44IILGo/HjouLA2DFihW89dZbja+LjY1tc93z58/HbrcDUFFRwbXXXktWVhZKKerq6hrXe8sttzR2yTS839VXX83rr7/O9ddfz5o1a3j11Vd99BOL01Fd5+RA6TH2lVSxt+Qoe4uPsq/ETIeP1jYu18NhJy0pigvSEhmWFMWwpGjSkqLoG9NDwlr4RJftxPWmJe0Pn3/+OStWrGDNmjVEREQwbdo0xo8fz+7du71eh+dX4KbHcUdGRjbe/93vfsf06dNZtmwZ+/fvZ9q0aa2u9/rrr+dHP/oR4eHhzJ8/X/rgLZJXfpyM/YdZt+8wGfvLyCyqPKl7JDE6jMEJkVw8OonUhEiGJJrwTu7VA5sEt/AjSYQmKioqiI2NJSIigt27d7N27Vqqq6v58ssv2bdvX2OXS1xcHDNnzuSZZ57hz3/+M2C6XGJjY0lKSmLXrl0MHz6cZcuWER3d/N7siooKkpOTAXj55Zcb58+cOZPnnnuO6dOnN3a5xMXF0a9fP/r168fixYtZsWKF37eFMIe9ZRVVucP7MOv3l5FXfhyAyFA7EwfFcvHoJIb0jmJwQhQpCRFEh8tQCcIaEuhNzJo1i7/97W+MHDmS4cOHc9ZZZ5GYmMiSJUuYN28eLpeL3r1789lnn/HAAw9w2223MWbMGOx2Ow899BDz5s3j0UcfZfbs2SQmJpKent64g7SpX//611x77bUsXryYSy+9tHH+jTfeSGZmJuPGjcPhcHDTTTdx++23A3DVVVdRXFzMyJEjO2V7dEd1Thfr9h3m0x0FrNhV1BjgCVFhTEmN5cbzU5mcEseIPtGEdLGdYqJ7U7qtI/T9JD09XTe9wMWuXbskqNpw++23M2HCBG644YZOeb/u8jupqqnni++L+WxnAat2F3Gkup6wEBvnpyXyg5G9OWtwPIPiI+SIEmE5pdQGrXV6c89JCz2ATJo0icjISB5//HGrSwkKldV1fLqjkA+2HuKb7FJqnS5iIxxcNLoPM0clcX5aAhGh8i8iAof8tQaQDRs2WF1CwKupd/L598Us33yIFbsKqal3kdyrB1efPYiLRiUxaVCsdKOIgCWBLoKe06VZu7eUf23O46PtBVRW1xMfGcqCyQOYO74fEwfGSleKCAoS6CIoaa3ZcegI723KY/mWQxRV1hAZaufiMX2YOz6Zc4fES0tcBB0JdBFUcg4fY/mWQyzblEd2URUOu2L68N7MHZ/MjJG9CXfYrS5RCL+RQBcBr+J4Hf/ems97m/JYt98MyzA5JZZHLh/DpWP70isi1OIKhegcEugiYFVW1/Hi1/t54au9VNbUMyQxkl9dPJw5Z/RjQFyE1eUJ0ekk0E+D56iKovNU1zl5dc1+nv18D2XH6rh4dBK3TR/K2OQY2bkpujUJ9CDQXcZWr6138fb6g/xlVTZFlTVcMCyRX140jHH9e1ldmhBdQtdNgY/uhYJtvl1nn7FwyaMtPn3vvfcyYMAAbrvNDB758MMPExISwurVqykrK6Ouro7Fixczd+7cNt+qqqqKuXPnNvu6V199lcceewylFOPGjeO1116jsLCQW265hb179wLw7LPP0q9fP2bPns327dsBeOyxx6iqquLhhx9uHDTs66+/ZuHChQwbNozFixdTW1tLfHw8b7zxBklJSc2O2V5RUcHWrVsbx6B5/vnn2blzJ0888cRpbV5/cbo0yzbl8ecVmeSWHWdySix/WTiBMwfHW12aEF1K1w10CyxYsICf//znjYH+zjvv8Mknn3DnnXfSs2dPSkpKOOuss5gzZ06bX+3Dw8NZtmzZKa/buXMnixcv5ttvvyUhIaFxbPU777yTqVOnsmzZMpxOJ1VVVW2Or15bW0vD8AllZWWsXbsWpRQvvPACf/rTn3j88cebHbPd4XDwyCOP8D//8z84HA5eeuklnnvuudPdfH7hcmlue2MjH+8oYExyTxZfNoapwxKla0WIZnTdQG+lJe0vEyZMoKioiEOHDlFcXExsbCx9+vTh7rvv5ssvv8Rms5GXl0dhYSF9+vRpdV1aa+6///5TXrdq1Srmz59PQkICcGKs81WrVjWOb26324mJiWkz0BcsWNB4Pzc3lwULFpCfn09tbW3j2O0tjdl+4YUX8sEHHzBy5Ejq6uoYO3ZsO7dW53hyZRYf7yjgVxcP59ZpQyTIhWhF1w10i8yfP5+lS5dSUFDAggULeOONNyguLmbDhg04HA5SUlJOGeO8OR19naeQkBBcLlfj49bGVr/jjju45557mDNnDp9//jkPP/xwq+u+8cYb+eMf/8iIESO4/nqfXGTK5z7ens+TK7O4YmJ/CXMhvCCnyjWxYMEC3nrrLZYuXcr8+fOpqKigd+/eOBwOVq9ezYEDB7xaT0uvu/DCC/nHP/5BaWkpQGOXy4wZM3j22WcBcDqdVFRUkJSURFFREaWlpdTU1PDBBx+0+n4NY6u/8sorjfMbxmxv0NDqP/PMM8nJyeHvf/87Cxe2elEqS+wuOMI972xh/IBePHL5GAlzIbwggd7E6NGjqaysJDk5mb59+3LVVVeRkZHB2LFjefXVVxkxYoRX62npdaNHj+a3v/0tU6dO5YwzzuCee+4B4Mknn2T16tWMHTuWSZMmsXPnThwOBw8++CBTpkxh5syZrb73ww8/zPz585k0aVJjdw7AAw88QFlZGWPGjOGMM85g9erVjc/95Cc/4dxzz/Xq0nmd6fDRWm58JYOosBCeu3qSnN0phJdkPPRubPbs2dx9993MmDGjxWU6+3dS53Rxzf+tY8PBMt65+WzGD5BDEoXw1Np46NJC74bKy8sZNmwYPXr0aDXMrfDIv3exZm8p/3X5WAlzIdpJdoqepm3btnH11VefNC8sLIzvvvvOoora1qtXLzIzM60u4xRvrz/Iy9/u58bzUrliUn+ryxEi4HS5QNdaB9QOsLFjx7J582ary/CLzuyO23DgMA+8t53z0xK49xLv9lMIIU7WpbpcwsPDKS0t7dQgEc3TWlNaWkp4eLjf36vwSDU3v7aR5F49eHrhRBmnXIgO6lIt9P79+5Obm0txcbHVpQjMB2z//v7v+njx632UH6vlzZvOJybC4ff3EyJYdalAdzgcjWc4iu6hYZyW6SN6k5YUbXU5QgQ0+W4rLPVNdglFlTVcMTHZ6lKECHgS6MJS727MJaaHg+kjeltdihABTwJdWKaqpp6PdxQwe1xfwkLkbFAhTpcEurDMR9vyqa5zMW+iHHMuhC9IoAvLvLsxj5T4CCYOlDNChfAFrwJdKTVLKfW9UipbKXVvM88PUkqtVEptVUp9rpSSJpdoVW7ZMdbsLWXexP4BdSKZEF1Zm4GulLIDzwCXAKOAhUqpUU0Wewx4VWs9DvgD8F++LlQEl39tPgTA5RPk6BYhfMWbFvoUIFtrvVdrXQu8BTS9qOYoYJX7/upmnheikdaaf27MZUpqHAPiIqwuR4ig4U2gJwM5Ho9z3fM8bQHmue9fDkQrpU65gq9SapFSKkMplSFng3ZfW3Ir2Ft8VI49F8LHfLVT9JfAVKXUJmAqkAc4my6ktV6itU7XWqcnJib66K1FoHl3Yy5hITYuGdvX6lKECCrenPqfBwzweNzfPa+R1voQ7ha6UioKuEJrXe6rIkXwqK13sXzLIS4a3Yee4TJuixC+5E0LfT2QppRKVUqFAlcCyz0XUEolKKUa1nUf8KJvyxTBYvX3RZQfq2OedLcI4XNtBrrWuh64HfgE2AW8o7XeoZT6g1JqjnuxacD3SqlMIAl4xE/1igD37sZcEqLCOH9oQtsLCyHaxavRFrXWHwIfNpn3oMf9pcBS35Ymgk3Z0VpW7S7imrNTZMxzIfxA/qtEp/lg6yHqnFq6W4TwEwl00Wn+uTGPEX2iGdW3p9WlCBGUJNBFp9hTXMXmnHLmTUyWU/2F8BMJdNEplm3Mw6Zg7njpbhHCXyTQhd8dr3WybFMe56UlktTT/xedFqK76lLXFBXBoaqmnoz9h1m37zDf7TvM1txy6pya+3840urShAhqEujitJUdrWXDgTK+21fKun2H2X7oCE6XJsSmGNc/hhvOG8x5QxM4L60Dx55rDaV7oDIfonpDVBKEx4D0wwtxCgl00S5aaw6UHmP9/sNsOFBGxoEysouqAAgNsTF+QC9umzaEKanxTBzUi4jQdv6JuVxQvAsOfAsHvjG3VYUnLxMSfiLco5Igug/0iIXQKAiLgtBo963HY0cPCAlzT+FgD/XNh4LWZrL5sffS5YLqcjhaAkeLPaYSMx8A5f553LcN9+2h5gOwRy8I73XitmFeSA/QLsD9c3jeR4OzDuqrob7GPVWfuHXWmvWHRprt64hwTz3MPLsDXE6zXH2NWZezxuN+rXk/7TTv53J6PHa563eAzQH2EPNeDfdtDnDVQd1xqDsGtcfc94+6b4+b14b0AEd4M7eek/vvwhbS8t9E05/DZoewnqYWb2lttlv1EQiNgLDo0/ijaJ4EumjTkeo63t9yiK8yS8g4UEZJVQ0AMT0cTBoUy7yJyaQPimNc/xjCHR24NmhNFWx8BfZ/bQK8IaR6JkPqVBh0DsSlmgCrLDABX1Vo7pfuMcF/vBzQ7Xtfe9iJf+iwKPMPFtbTPUVDuPs2JByqK+B4mZmOHT5x/3iZWVdsCsQPgbjB7inV3MYMbN8/PZh/+L2rIfNT2PeF+Xbiqm9+2bAYUJz4YGkazA2haQlFu38nVlK2E38Pyn7iQ8dZ0/I2dESav5PwGPN3E+7++3HVQ80R83dT7b6tOWLWBzD7z5B+vc9/BAl00SytNRkHynhrXQ7/3naI6joX/WN7cEFaApNSYpmcEsfQxChsNh+0cre8CZ/cD7GpMHI2DDrXTL0Get+K1tq01GqqoLYKairdt+7HdcdPtA49W5n1te4W3lHzD1dTCeUHTtyvPmJajI5I8y2gR6xp2SYON/cj4sw/++F9Ztr3lWklNrCFmJ+r9whIHGle13skxA81wdFQe2k2ZH4CWZ/AgTWm9RkeA4OnQdwQiEx0Twkn7kfEt/1hobX75yg3H3rVFR73y812aGzZ205u5aNOtF7tHt9uPL/lOGuatJCPnZjqa0xLOiTULNswhYSdaHnb7CY8bXb3Nwu7qcNmN9vVWWfC0Vlntomz7sR9m8O0dBu+FTgavim4p4ZvF3XHm7/1/NbR9G/DVd98zQ2PXU6PwK44EdjHSs3fgd1hgj0i3nywh7lDvyH8B57d7n8Tb0igi5OUVtXw7sY83lp/kD3FR4kKC2HexP5cOXkAY5Nj/HMMefFu8wd/56aOd4MoZb7mh0ZihhPyEa3d/9xejgyptfn2cHivmUr3QEkmFO2G3R+aDwcwwRU3GBLSoGgXlO0z8xNHwtm3QtrFMODM9rfum1LKHSI9zQekCGoS6N2c06XZV1LFtrwKPttZyGc7C6lzaiYNiuV/fjyES8f1bX8/eHuVZJkWa1fc0amU92HesHx0HzMNOufk5+przM9avNtMRbvM44Q0OPs2SLsIYgf5tn7RrUigdyNOl2ZPcRXbcivYllfB9rwKduYf4VitaTXGRYZy7dkpLJg8gLQk3++waVFpNqSc13nvZ5WQMOgzxkxC+IEEepCrOFbHyt2FfLS9gG+ySxrDu4fDzqh+PflJ+gDGJMcwNjmGIYmRnT8KYu1ROJIH8Wmd+75CBCEJ9CBUXFnDZzsL+Wh7Pmv2lFLv0vSNCeeKif2ZMLAXY5NjGJwYhd0XOzRPV2m2uY0fYm0dQgQBCfQgoLVmT/FRvsgs5pMdBazffxitISU+ghvPH8ysMX04o7+fdmierpIsc5sgLXQhTpcEeoAqrarhmz2lfJ1VzNdZJRyqqAZgeFI0d16YxqwxfRjRJ7prhrinhhZ6nLTQhThdEugBwunSfLevlC8yTYDvOHQEgJ7hIZwzJIFbpydwfloCg+IjLa60nUqyIGaAOZ5YCHFaJNC7MK01W3Ir+NfmPD7Ymk9xZQ0Ou2LCwFh+MXMY56UlMK5/r67RF95RpdnmkEUhxGmTQO+CsosqWb75EP/acogDpccItduYPiKROWckM214IpFhQfJrazhDcvx/WF2JEEEhSJIh8B2tqeft9Tks3ZDLzvwj2BScMySB26YP5eLRfYjp0Y6TWwJFZYE5LV8OWRTCJyTQLVZ2tJZX1uzn5W/3U36sjjMG9OKhH43i0nF96R0d5BeDKG04wkW6XITwBQl0ixRUVPP8V3t5c91BjtU6+cHIJG6dPoSJA2OtLq3zNByyKC10IXxCAr2T7S2u4rkv9vLuplxcGuac0Y9bpg5heJ9OPNW+qyjNNuNT95TrjArhCxLonWRPcRV/XpHFB1sPEWq3ceXkgSy6YDAD4rrx4XoNg3L58+IQQnQjEuh+dqD0KE+uzOK9TXmEO+zcfMEQbjgvlcToMKtLs15pFvSbYHUVQgQNCXQ/yS07xl9WZrN0Yy4Ou+LG8wdz8wWDiY+SIAfMULLlB2HsT6yuRIigIYHuYwUV1Ty9Oou31+egUFx91iBunTaE3j2D/IiV9jq811yRRsZwEcJnJNB9ZHteBa+vPcC7m/LQWvOT9AHcfuFQ+sb0sLq0rqnxCBc5ZFEIX5FAPw019U4+3JbPq2sOsOlgOT0cdn48qT8/mzqke+/s9EapBLoQvuZVoCulZgFPAnbgBa31o02eHwi8AvRyL3Ov1vpDH9faZeSWHeON7w7y9vocDh+tZXBCJA/OHsUVk/oH5xmd/lCSDVF9zLUuhRA+0WagK6XswDPATCAXWK+UWq613umx2APAO1rrZ5VSo4APgRQ/1GupbbkVPLkyi1W7CwGYOSqJq89K4dyh8V1/mNqupjRL+s+F8DFvWuhTgGyt9V4ApdRbwFzAM9A10NDUigEO+bJIqx0oPcpjn2by/pZDxEY4uHXaUP7jzIH06yX94x2itelDH3251ZUIEVS8CfRkIMfjcS5wZpNlHgY+VUrdAUQCP2huRUqpRcAigIEDB7a31k5XUlXD06uyeeO7A4TYbNxx4VAWXTCY6HDpVjktx0qhulxa6EL4mK92ii4EXtZaP66UOht4TSk1Rmvt8lxIa70EWAKQnp6uffTePne0pp7/+3ofz32xh+p6FwsmD+DnM9Lk0ENfkTFchPALbwI9Dxjg8bi/e56nG4BZAFrrNUqpcCABKPJFkZ2ltt7F2xk5PLkii5KqGmaN7sOvZg1nSGKU1aUFFxllUQi/8CbQ1wNpSqlUTJBfCTS9IsFBYAbwslJqJBAOFPuyUH+qqXfyTkYuz67O5lBFNZNTYnnu6klMGtSNRj7sTCVZYA+FXoOsrkSIoNJmoGut65VStwOfYA5JfFFrvUMp9QcgQ2u9HPgF8LxS6m7MDtLrtNZdtkulQXWdk7fX5/Ds53soOFLNpEGxPHrFOM5PS5CjVvypNBviBoPNbnUlQgQVr/rQ3ceUf9hk3oMe93cC5/q2NP+prnPy5rqD/O2LPRQeqWFySiyPzT9DDj/sLCVZkDjc6iqECDrd6kxRrTVvrsvhiRWZFFfWcGZqHE8sGM/ZgyXIO42zDsr2wcjZVlciRNDpNoFeXefkvne3sWxTHlNS4/jLwgmcNTje6rK6n7ID4KqXI1yE8INuEeh55ce5+bUMtucd4Rczh3Hb9KHYbNIit0TjES4S6EL4WtAH+nd7S7n1jY3U1Lt44Zp0fjAqyeqSujcZZVEIvwnaQNda8/raA/z+/Z0MjItgyTXpDO0tx5NbrjQbIuIhIs7qSoQIOkEZ6DX1Th58bwdvZ+Rw4Yje/PnK8fSU0/W7htJs6T8Xwk+CLtALj1Rzy+sb2HSwnNunD+WemcOkv7wrKcmCYRdZXYUQQSmoAj27qIpr/u87yo/X8derJvLDsX2tLkl4qq6Ao0XSQhfCT4Im0DfnlHP9S+uw2xTv3Hw2Y5JjrC5JNFWSbW7lCBch/CIoAv3LzGJueX0D8VGhvPbTM0lJiLS6JNGcUhllUQh/CvhA/9fmPH7xzhbSkqJ55frJMsRtV1aSBcoOsSlWVyJEUAroQH/pm338/v2dTEmN44Vr0wP/SJb6GhN49oD+tbSsNMuEeUio1ZUIEZQCMjm01jz+aSZPr87molFJPLVwAuGOAB+5r64alkyF6iNw3t0w8RpwBNm3jZJs6T8Xwo9sVhfQXvVOF/cv28bTq7O5cvIA/nrVxMAPc4Av/wTFuyEqET76FTw1Htb+DeqOW12Zb7hccHiPnCEqhB8FXKA/uTKLN9flcNv0IfzXvLGE2APuRzhVwXb45kk4YyEs+gKuWW7GC//4N/DkGbDmr1B7zOoqT09FDtRXSwtdCD8KuC6Xn56bysC4COanD2h74UDgcsL7d0J4DFz0CCgFg6eaaf/X8Pmj8Ml98PUTcO6dMGURhIRZXXX7yREuQvhdwDVvYyNDgyfMAdY9D3kbYNajENlkON+U8+C6D+D6j6D3SPj0Afjiv62ps/aYOTGoo+QYdCH8LuBa6EGlPAdW/gGGzICx81tebtA5cO1y+PuVsPE1mHYf2Nt5RE/OOvjqcfjxSxAa0b7Xag0vzYL8LRAzAHqPgqRR0Hs0JI02Id1WPaVZEBYDkYnte28hhNck0K2iNfz7F4CG2U+Yrpa2TLoWMj+CzI9h5I/a936r/wh7V8O2f5j1tMeBb02YN3zoFO6APSvNhSoAbA5IGAZDpsPoyyF50qk/T0kWJAz17ucUQnSIBLpVdiyDrE9Mv3nsIO9eM3QmRPeFDa+0L9CLM02Yo0wXz8Rr2hes618wffw/eupE676+1rS6C3eYqWArfPccrHkaeg00wT76cug73rxXaTaknO/9ewoh2k0C3QrHy+Cj35iwO/MW719nD4EJ/w++fMx01/Tycl/C+ufBHgpTfw2rFsPBtTDobO9eW1kIu5bDlJtP7qoJCTXdLUmjPX6uctj9b/NhteYZc+RO3GAYOQeO5JkWuhDCbwJup2hQ+PR3cKwU5jzV/rNCJ1xtbje97t3y1Udg899h9Dw461bT0l63xPv32/iq6VpJ/2nby5Z9oxAAABHkSURBVPboBROugv+3FH6ZZVr0vQbBt38xzyeO9P59hRDtJoHe2fZ9BZteg7Nvg75ntP/1sYNg8DQT6C5n28tveQtqq+DMRRAaaT4Qdi2HI/ltv9ZZDxtegsHT29+6jogzffXXvAe/zISFb8PwS9q3DiFEu0igd6a64/D+XWY8k2n3dXw9k66FI7mwZ1Xry2ltWuPJk8wEpqXtcsKGl9t+n8yPTFfJ5Bs7XitAZAIMnwW2IDijV4guTAK9M6152pz+PvuJ9h866Gn4pea6nG2F8t7PzY7LKTefmBc/BNJmmpZ3fW3rr1//AvTsD8NmdbxWIUSnkUDvTNkrof9kGHLh6a0nJNQME5D5sdlp2ZJ1S8xx36MvO3n+lEVQ5d7Z2ZKSLPOBkH5d8I7+KESQkUDvLC4XFGwzR7b4wsRrzc7KLX9v/vmyA/D9RzDpulOHChgyA2JTzSGMLcl40RxfPuEa39QrhPA7CfTOUrbP7JzsO84360scBgPPMUehaH3q8+tfAGWDSdef+pzNBlNugpy15oShpmqPwqY3YNQciE7yTb1CCL+TQO8sDcHZx0eBDmbn6OG9sP+rk+fXHjNBP3I2xCQ3/9rx/wGOiOZb6duWQk0FTL7Jd7UKIfxOAr2zFGwFW4gZZMtXRs4x46NsfPXk+duXQnX5yTtDm+oRC+N+YoYCOHb4xHytzYlIvUfDwLN8V6sQwu8k0DtL/lZzYo0vh74NjTChvHP5iVBuOFSx92gzqFdrJt9kxij3PEkpN8P09U++QcZdESLAeBXoSqlZSqnvlVLZSql7m3n+CaXUZveUqZQq932pAUxr00L3Vf+5p0nXgrMGtr5tHh9cawL5zEVtB3KfMTDoXNPf3nCS0voXIDTafFAIIQJKm4GulLIDzwCXAKOAhUqpUZ7LaK3v1lqP11qPB/4CvOuPYgNWZQEcLfZt/3mDPmOh3wQzYFdD6zw8pvXheD1NWQTlByDrMzhaAjvehfELISza97UKIfzKmxb6FCBba71Xa10LvAXMbWX5hcCbviguaBRsNbf+aKGDOYSxeBfset8cWz7hanOavzdGXArR/cwHwabXwFkL6Tf4p04hhF95E+jJQI7H41z3vFMopQYBqUCz56QrpRYppTKUUhnFxcXtrTVw5bsDPWmMf9Y/9sfgiIT3fma6Tia3I5DtDjMcwJ6V8O3TZojb3iP8U6cQwq98vVP0SmCp1rrZUaO01ku01ula6/TExG505ZqCLWYY2fCe/ll/WDSMmWeOc0+7yLxXe0y61pxEdKykfR8GQoguxZtAzwM8B97u757XnCsJ9u6Wqg58s8jf6p/+c0+TbwR7GJxzR/tfG9Ubxi2AmIEwYrbvaxNCdApvAn09kKaUSlVKhWJC+5RBQJRSI4BYYI1vS+xCcjfAY2nmkmzeOl5udjr6q/+8Qb/xcF8upHbwqkCzn4CffdP+a5UKIbqMNgNda10P3A58AuwC3tFa71BK/UEpNcdj0SuBt7Ru7jz0ILFnFaDNVXm8VbDN3PbpwNjn7RUSenqv9VeXkBCiU3g1jJ7W+kPgwybzHmzy+GHfldVFHXR/+cheCRc/4t1r/H2EixBCuMmZot5yOSFnnRn/pHgXVLS0G6GJ/K0Q1cf0UwshhB9JoHurcAfUVpoTcaDtqwU18NcZokII0YQEurcaulsm32Ba3HtWtv2auuNQ/L3/j3ARQggk0L13cI25HFuvgeaKQ3tWt32R5qKdoJ3SQhdCdAoJdG9obQa9GnS2eTx0hhme9tCm1l/XcIaotNCFEJ1AAt0bZfuhMv/E+OCDpwPKHO3SmoKtZrzy2BQ/FyiEEBLo3jm41twOdLfQI+PNiTxt9aPnbzWjIcq44kKITiCB7o2Da8yQtIkeVxsaMsNcDOJ4C0O/u5zmyBjpPxdCdBIJdG8cXAMDzjIXV24wdIbZ4bnvi+ZfU5IF9cel/1wI0Wkk0NtytARKMk+9vmb/yebKPi31o8sZokKITiaB3pac78xtQ/95A7sDBk81Jxg1N3xN/hYz+mHCMP/XKIQQSKC37cC3JpiTJ5763JALoSLHdK80VbAVkkbJ6IVCiE4jgd6Wg2tNmIeEnfrc0BnmtunRLlp3zhjoQgjhQQK9NbXHIH/zqf3nDWJTIH7oqf3oFTnmxCPpPxdCdCIJ9NbkZYCrHgae0/IyQ2bA/q+hrvrEvMYzRDthDHQhhHCTQG/NwbWAggGTW15m6AxzeOJBjws1FWwFZYOk0X4vUQghGkigt+bgGug9CnrEtrxMynlgDz25Hz1/K8SnQWiE/2sUQgg3CfSWOOvNBS0Gnd36cqGRpo8922N8dBkDXQhhAQn0lhRuh9qqU48/b86QGVC0A47kw9FSOJInR7gIITqdBHpLGgfkauEIF0+Nhy+ugoIt5r600IUQncyri0R3SwfXQMwAiOnf9rJJYyAqyfSjN7TMpYUuhOhkEujN0doEeupU75ZXypw1mvkJaJf5IIiI82+NQgjRRPfrcvnqf2Hz31tfpmwfVBV6193SYMgMOH4Yvv9IWudCCEt0rxb6jmWw8vfm/rHDcM7tzS/X9IIW3hjivopRfbX0nwshLNF9WuiVBfDB3dBvIoy6DD79LXz9RPPLHvgWwntB4gjv1x+ZAH3dZ4ZKC10IYYHu0ULXGpbfAXXHYd4SiE0FWwiseNgcbz71Vycvf3Ct6W6xtfPzbugPzNgvfeWUfyFE5+segb7hZcj6FC75EySkmXnzlphQX73YjNcy7V6zc/NoCZRmwYSr2v8+595lPghikn1avhBCeCP4A/3wXvjktzB4Gky+6cR8mx0u+6sJ9S8eBVcdXPi7E2OytDYgV0vCe0LaTF9ULYQQ7Rbcge5ywrKfmdCe+8ypXSg2O8z5C9hD4KvHwVlnXmMPg37jralZCCE6KLgD/dunIGctzHu+5ROEbDa49AkT+t8+5b460aTmL2ghhBBdmFd7/ZRSs5RS3yulspVS97awzE+UUjuVUjuUUm0c6N0JCrbBqkdg1FwYO7/1ZW02+OFjcObPwFnT9oBcQgjRBbXZQldK2YFngJlALrBeKbVca73TY5k04D7gXK11mVKqt78K9kp9Dbx7sxn29tInzM7OtigFs/7LHE8+qAP950IIYTFvWuhTgGyt9V6tdS3wFjC3yTI3Ac9orcsAtNZFvi2znVY/YkY/nPs0RMZ7/zqlYNjFEBbtv9qEEMJPvAn0ZCDH43Gue56nYcAwpdQ3Sqm1SqlZza1IKbVIKZWhlMooLi7uWMVtObAGvnkKJl5rwlkIIboJX50pGgKkAdOAhcDzSqleTRfSWi/RWqdrrdMTExN99NZNfPsURPeBi//on/ULIUQX5U2g5wEDPB73d8/zlAss11rXaa33AZmYgO98hzZB6gUQFmXJ2wshhFW8CfT1QJpSKlUpFQpcCSxvssx7mNY5SqkETBfMXh/W6Z3KQqjMl1PvhRDdUpuBrrWuB24HPgF2Ae9orXcopf6glJrjXuwToFQptRNYDfxKa13qr6JblN9wtSA5KUgI0f14dWKR1vpD4MMm8x70uK+Be9yTdRoCvc9YS8sQQggrBNfwufmbIX6oGVNFCCG6mSAL9C3Sfy6E6LaCJ9CPlkJFjvSfCyG6reAJ9PzN5lZGSRRCdFPBF+hy+TchRDcVRIG+xVxarscpJ6gKIUS3EDyBfkiu5SmE6N6CI9CPl0H5Aek/F0J0a8ER6I1niEoLXQjRfQVZoEsLXQjRfQVHoB/aDDEDISLO6kqEEMIywRHo+Vugn3S3CCG6t8AP9OoKOLxH+s+FEN1e4Ad6wTZz23eCtXUIIYTFAj/QD7nPEJUWuhCimwv8QM/fAj2TIcpP1ygVQogAEQSBLmeICiEEBHqg11RBSZYcfy6EEAR6oBdsA7S00IUQgkAP9IYzRGUMFyGECPRA3wxRSRDdx+pKhBDCcgEe6Fuk/1wIIdwCN9Brj0Hxbuk/F0IIt8AN9MIdoF3Sfy6EEG6BG+j5coaoEEJ4CuxAj0gwZ4kKIYQI4EA/tMV0tyhldSVCCNElBGag11VD8S7pbhFCCA+BGehFO8BVL4csCiGEh8AMdLkotBBCnCIwA/3QZugRC70GWl2JEEJ0GV4FulJqllLqe6VUtlLq3maev04pVayU2uyebvR9qR7yt5jWuewQFUKIRm0GulLKDjwDXAKMAhYqpUY1s+jbWuvx7ukFH9d5Qn0tFO2U/nMhhGjCmxb6FCBba71Xa10LvAXM9W9ZrSjeBc5a6T8XQogmvAn0ZCDH43Gue15TVyiltiqlliqlBjS3IqXUIqVUhlIqo7i4uAPlcuIaonLKvxBCnMRXO0XfB1K01uOAz4BXmltIa71Ea52utU5PTOzgNUAjE2D4pRCb2uFihRAiGIV4sUwe4Nni7u+e10hrXerx8AXgT6dfWgtGXGomIYQQJ/Gmhb4eSFNKpSqlQoErgeWeCyil+no8nAPs8l2JQgghvNFmC11rXa+Uuh34BLADL2qtdyil/gBkaK2XA3cqpeYA9cBh4Do/1iyEEKIZSmttyRunp6frjIwMS95bCCEClVJqg9Y6vbnnAvNMUSGEEKeQQBdCiCAhgS6EEEFCAl0IIYKEBLoQQgQJy45yUUoVAwc6+PIEoMSH5fiS1NYxUlvHSG0dE8i1DdJaN3uqvWWBfjqUUhktHbZjNamtY6S2jpHaOiZYa5MuFyGECBIS6EIIESQCNdCXWF1AK6S2jpHaOkZq65igrC0g+9CFEEKcKlBb6EIIIZqQQBdCiCARcIGulJqllPpeKZWtlLrX6no8KaX2K6W2KaU2K6UsHUpSKfWiUqpIKbXdY16cUuozpVSW+za2C9X2sFIqz73tNiulfmhRbQOUUquVUjuVUjuUUne551u+7VqpzfJtp5QKV0qtU0ptcdf2e/f8VKXUd+7/17fd11ToKrW9rJTa57HdLLuupVLKrpTapJT6wP24Y9tNax0wE2Y89j3AYCAU2AKMsrouj/r2AwlW1+Gu5QJgIrDdY96fgHvd9+8F/rsL1fYw8MsusN36AhPd96OBTGBUV9h2rdRm+bYDFBDlvu8AvgPOAt4BrnTP/xvwsy5U28vAj63+m3PXdQ/wd+AD9+MObbdAa6FPAbK11nu11rXAW8Bci2vqkrTWX2IuNuJpLieu9/oKcFmnFuXWQm1dgtY6X2u90X2/EnP1rWS6wLZrpTbLaaPK/dDhnjRwIbDUPd+q7dZSbV2CUqo/cCnm8p0opRQd3G6BFujJQI7H41y6yB+0mwY+VUptUEotsrqYZiRprfPd9wuAJCuLacbtSqmt7i4ZS7qDPCmlUoAJmBZdl9p2TWqDLrDt3N0Gm4EizMXi9wDlWut69yKW/b82rU1r3bDdHnFvtyeUUmFW1Ab8Gfg14HI/jqeD2y3QAr2rO09rPRG4BLhNKXWB1QW1RJvvcl2mlQI8CwwBxgP5wONWFqOUigL+Cfxca33E8zmrt10ztXWJbae1dmqtx2MuJD8FGGFFHc1pWptSagxwH6bGyUAc8JvOrkspNRso0lpv8MX6Ai3Q84ABHo/7u+d1CVrrPPdtEbAM80fdlRQ2XNDbfVtkcT2NtNaF7n86F/A8Fm47pZQDE5hvaK3fdc/uEtuuudq60rZz11MOrAbOBnoppRquXWz5/6tHbbPcXVhaa10DvIQ12+1cYI5Saj+mC/lC4Ek6uN0CLdDXA2nuPcChwJXAcotrAkApFamUim64D1wEbG/9VZ1uOXCt+/61wL8srOUkDWHpdjkWbTt3/+X/Abu01v/r8ZTl266l2rrCtlNKJSqlernv9wBmYvr4VwM/di9m1XZrrrbdHh/QCtNH3enbTWt9n9a6v9Y6BZNnq7TWV9HR7Wb13t0O7A3+IWbv/h7gt1bX41HXYMxRN1uAHVbXBryJ+fpdh+mDuwHTN7cSyAJWAHFdqLbXgG3AVkx49rWotvMw3Slbgc3u6YddYdu1Upvl2w4YB2xy17AdeNA9fzCwDsgG/gGEdaHaVrm323bgddxHwlg1AdM4cZRLh7abnPovhBBBItC6XIQQQrRAAl0IIYKEBLoQQgQJCXQhhAgSEuhCCBEkJNCFECJISKALIUSQ+P95xcDHa7JV+gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ymDk6ps-yBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}